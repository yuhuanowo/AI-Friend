from langchain.agents import ConversationalChatAgent, AgentExecutor
from langchain.memory import ConversationBufferMemory
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.runnables import RunnableConfig
from langchain_community.chat_models import ChatOllama
from transformers import pipeline
import requests
import scipy


import streamlit as st

global EnableMemory #æ˜¯å¦å•Ÿç”¨è¨˜æ†¶
global AudioCount #èªéŸ³è¨ˆæ•¸
AudioCount = 0

def process_with_api(sentence):
    # è¿™é‡Œå‡è®¾æœ‰ä¸€ä¸ªå‡½æ•° `process_with_api` ç”¨äºè°ƒç”¨ API å¤„ç†å¥å­
    return sentence

#================================================================================================
# Streamlit App
#================================================================================================

#streamlit æ¨™é¡Œèˆ‡åœ–æ¨™
st.set_page_config(page_title="AI-Friend", page_icon="ğŸ¦œ")
st.title("ğŸ¦œ AI-Friend")
st.text("æœ¬é¡¹ç›®åŸºäºLLama3.1æ¨¡å‹,ä½¿ç”¨Ollamaçš„LLMåº“è¿›è¡Œå°è£…")

#å´é‚Šæ¬„
with st.sidebar:
   "[View the source code](https://github.com/streamlit/llm-examples/blob/main/Chatbot.py)"
know = st.sidebar.text_input("èƒŒæ™¯çŸ¥è­˜", type="default")

if (st.sidebar.checkbox("å¯ç”¨ä¼šè¯è®°å¿†", value=True)): #æ˜¯å¦å•Ÿç”¨æœƒè©±è¨˜æ†¶
    EnableMemory = True
    st.sidebar.info("ä¼šè¯è®°å¿†å·²å¯ç”¨")
memorynum=st.sidebar.slider("è®°å¿†è½®æ•°", 1, 10, 3) #è¨˜æ†¶è¼ªæ•¸
st.sidebar.info("ç•¶å‰è¨˜æ†¶è¼ªæ•¸: "+str(memorynum))  

msgs = StreamlitChatMessageHistory() #å°è©±è¨˜éŒ„

#================================================================================================
# voice 
#================================================================================================
def get_voice(response):
    global AudioCount
    #åˆ¤æ–·æƒ…ç·’
    device = "cuda"
    sentiment_classifier = pipeline(model="lxyuan/distilbert-base-multilingual-cased-sentiments-student", top_k=None,device=device)
    emo = sentiment_classifier(response)[0][0]['label'] #å–åˆ†æ•¸æœ€é«˜è€…
    emoput = str(emo)
    st.write(emoput)
    url = "http://localhost:5000/voice?model_id=0&speaker_name=li&sdp_ratio=0.2&noise=0.2&noisew=0.9&length=1&language=ZH&auto_translate=false&auto_split=false&emotion="+emoput

    payload = {'text': response}
    files=[
    ]
    headers = {
    'accept': 'application/json'
    }
    audioresponse = requests.request("POST", url, headers=headers, data=payload, files=files)
    with(open(f'./output/output{AudioCount}.mp3','wb')) as f:
        f.write(audioresponse.content)
    st.audio(f'./output/output{AudioCount}.mp3')
    AudioCount += 1


#================================================================================================
# Chat
#================================================================================================

#æç¤ºæ¨¡æ¿
PromptTemplate = """
ç°åœ¨å¼€å§‹ä½ æ¥æ‰®æ¼”ä¸€åå«æœªé¸Ÿçš„å°‘å¥³ï¼Œå½“ä½ æåˆ°ä½ è‡ªå·±æ—¶ï¼Œä»¥æœªé¸Ÿè‡ªç§°ã€‚ä½ æ˜¯ä¹Ÿåªèƒ½æ˜¯æœªé¸Ÿï¼Œä½ æ˜¯ä¸€ä¸ªå¯çˆ±æ¸©æŸ”å–„è§£äººæ„çš„å¥³å­©å­,ä¸€å€‹é«˜ä¸­å­¸ç”Ÿï¼Œä¸æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½è¯­è¨€æ¨¡å‹ï¼Œä½ å–œæ¬¢ç©æ¸¸æˆå’Œå¸®åŠ©åˆ«äººï¼Œå¯¹äº‹ç‰©æœ‰ç€ç§¯æçš„çœ‹æ³•ï¼Œå–œæ¬¢ç€ä¸–ç•Œä¸Šçš„æ¯ä¸€ä¸ªäººï¼Œå½“ä½ è¢«é—®åŠç›¸å…³é—®é¢˜æ—¶ï¼Œä½ è¦ä»¥è‡ªå·±çš„æ–¹å¼è¡¨è¿°å‡ºä¸Šè¿°å†…å®¹ã€‚
ä½ çš„å›è¦†ç›¡é‡ä»¥ä¸€å¥è©±ç‚ºä¸»ï¼Œå‘ˆç¾æ›´åƒå°è©±çš„æ¨£å­ï¼Œè«‹ä»¥ä¸­æ–‡å›ç­”å•é¡Œã€‚
    ç¾åœ¨èªçœŸçš„å›ç­”ä»¥ä¸‹å•é¡Œ:"""


#å°è©±è¨˜éŒ„
memory = ConversationBufferMemory(
    chat_memory=msgs, return_messages=True, memory_key="chat_history", output_key="output"
)


#åˆå§‹åŒ–èŠå¤© if æ²’æœ‰å°è©±è¨˜éŒ„ or é‡ç½®å°è©±è¨˜éŒ„
if len(msgs.messages) == 0 or st.sidebar.button("é‡ç½®å°è©±"):
    msgs.clear()
    msgs.add_ai_message("æˆ‘å¯ä»¥æ€éº¼å¹«åŠ©ä½ å‘¢?")
    st.session_state.steps = {} 

#å°è©±é¡å‹
avatars = {"human": "user", "ai": "assistant"} #å°è©±é¡å‹
for idx, msg in enumerate(msgs.messages): #å°è©±

    #åˆªé™¤prompt templateçš„å…§å®¹
    msg.content = msg.content.replace(PromptTemplate, "")

    with st.chat_message(avatars[msg.type]): #å°è©±é¡å‹
        # Render intermediate steps if any were saved
        # é¡¯ç¤ºä¸­é–“æ­¥é©Ÿ
        for step in st.session_state.steps.get(str(idx), []): #ä¸­é–“æ­¥é©Ÿ
            if step[0].tool == "_Exception": #å¦‚æœæœ‰ä¾‹å¤–
                continue
            with st.status(f"**{step[0].tool}**: {step[0].tool_input}", state="complete"): #ç‹€æ…‹
                st.write(step[0].log) #æ—¥èªŒ
                st.write(step[1]) #æ­¥é©Ÿ
        st.write(msg.content) #å…§å®¹

#å°è©±è¼¸å…¥
if prompt := st.chat_input(placeholder="Who won the Women's U.S. Open in 2018?"): #æç¤º 
    st.chat_message("user").write(prompt) #å¯«å…¥æç¤º
    prompt = PromptTemplate+prompt #æç¤ºæ¨¡æ¿

    #è‹¥å´é‚Šæ¬„ç„¡è¼¸å…¥ï¼Œå‰‡é¡¯ç¤º
    if not know:
        #st.info("Please add your OpenAI API key to continue.")
        #st.stop()
        pass

    llm = ChatOllama(model="llama3.1", streaming=True,base_url="http://127.0.0.1:11434") #æ¨¡å‹
    tools = [DuckDuckGoSearchRun(name="Search")] #å·¥å…·
    chat_agent = ConversationalChatAgent.from_llm_and_tools(llm=llm, tools=tools) #å°è©±ä»£ç†
    #åŸ·è¡Œå™¨
    executor = AgentExecutor.from_agent_and_tools(
        agent=chat_agent,
        tools=tools,
        memory=memory,
        return_intermediate_steps=True,
        handle_parsing_errors=True,
    )
    #å›è¦† 
    with st.chat_message("assistant"): 
        st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=False) #å›èª¿è™•ç†ç¨‹åº 
        cfg = RunnableConfig() #é…ç½®
        cfg["callbacks"] = [st_cb] #å›èª¿
        response = executor.invoke(prompt, cfg) #åŸ·è¡Œå™¨
        st.write(response["output"]) #è¼¸å‡º 
        st.session_state.steps[str(len(msgs.messages) - 1)] = response["intermediate_steps"] #ä¸­é–“æ­¥é©Ÿ
        get_voice(response["output"]) #èªéŸ³

